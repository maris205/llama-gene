{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a2413e-8629-4016-aace-17d2f757f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# 打印环境变量以确认设置成功\n",
    "print(os.environ.get('HF_ENDPOINT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e2d33a-6d84-4ef3-b44e-daa57ac81e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 14:38:54.395411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 14:38:54.410195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 14:38:54.425354: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 14:38:54.429861: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 14:38:54.444520: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 14:38:55.307233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig,AutoModel\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import  AutoConfig, AutoModelForCausalLM,LlamaForCausalLM,LlamaTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fc5c44-b444-402e-aaf2-0ba4e2000e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 6991\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dna_ft_dataset = load_dataset('json', data_files='protein_sft_eva.json')\n",
    "dna_ft_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab4fd3e-5b59-470e-9b46-f0ffd7b9d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 699\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 6292\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dna_ft_dataset[\"train\"].train_test_split(train_size=0.1, seed=42)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ca97f5-6864-4d6f-944a-182ed1fa2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"genehlm-llama-7b-sft-v0\") #dnagpt/dnahlm-llama-7b-sft-v0\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e904c0b2-bf21-4036-b510-8e57177c1767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39ffae38bd647b992c6358453313cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(91598, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=91598, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\"genehlm-llama-7b-sft-v0\") #continue pretrain\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b361c5c-c43f-4ed9-a5c7-c72403cd7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建提示词\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text + \"\\n\\n### Response:\\n\"\n",
    "\n",
    "#构建提示词\n",
    "def build_prompt(entry):\n",
    "\n",
    "    input_data = format_input(entry)\n",
    "\n",
    "    desired_response = entry['output']\n",
    "\n",
    "    return input_data + desired_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed031a26-d79e-4f50-85d1-169ebd409c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Determine the Prokaryotic Protein Subcellular Location of following protein sequence, The result will be one of the following: CYtoplasmicMembrane,Cellwall,Cytoplasmic,Extracellular,OuterMembrane,Periplasmic.',\n",
       " 'input': 'MKIGIPKEIKNNENRVAMTPAGVVSLTHAGHERLAIETGGGIGSSFTDAEYVAAGAAYRCIGKEAWAQEMILKVKEPVASEYDYFYEGQILFTYLHLAPRAELTQALIDKKVVGIAYETVQLANGSLPLLTPMSEVAGKMATQIGAQYLEKNHGGKGILLGGVSGVHARKVTVIGGGIAGTNAAKIAVGMGADVTVIDLSPERLRQLEDMFGRDVQTLMSNPYNIAESVKHSDLVVGAVLIPGAKAPKLVSEEMIQSMQPGSVVVDIAIDQGGIFATSDRVTTHDDPTYVKHGVVHYAVANMPGAVPRTSTIALTNNTIPYALQIANKGYKQACIDNPALKKGVNALEGHITYKAVAEAQGLPYVNVDELIQ',\n",
       " 'output': 'Cytoplasmic'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data[\"test\"][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bd4bb5-86a6-4046-b510-492b0548323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Determine the Prokaryotic Protein Subcellular Location of following protein sequence, The result will be one of the following: CYtoplasmicMembrane,Cellwall,Cytoplasmic,Extracellular,OuterMembrane,Periplasmic.\n",
      "\n",
      "### Input:\n",
      "MKIGIPKEIKNNENRVAMTPAGVVSLTHAGHERLAIETGGGIGSSFTDAEYVAAGAAYRCIGKEAWAQEMILKVKEPVASEYDYFYEGQILFTYLHLAPRAELTQALIDKKVVGIAYETVQLANGSLPLLTPMSEVAGKMATQIGAQYLEKNHGGKGILLGGVSGVHARKVTVIGGGIAGTNAAKIAVGMGADVTVIDLSPERLRQLEDMFGRDVQTLMSNPYNIAESVKHSDLVVGAVLIPGAKAPKLVSEEMIQSMQPGSVVVDIAIDQGGIFATSDRVTTHDDPTYVKHGVVHYAVANMPGAVPRTSTIALTNNTIPYALQIANKGYKQACIDNPALKKGVNALEGHITYKAVAEAQGLPYVNVDELIQ\n",
      "\n",
      "### Response:\n",
      "Cytoplasmic\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt(example)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0b5b8b-916c-499b-a6da-f1124b9add1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Below',\n",
       " '▁is',\n",
       " '▁an',\n",
       " '▁instruction',\n",
       " '▁that',\n",
       " '▁describes',\n",
       " '▁a',\n",
       " '▁task',\n",
       " '.',\n",
       " '▁Write',\n",
       " '▁a',\n",
       " '▁response',\n",
       " '▁that',\n",
       " '▁appropri',\n",
       " 'ately',\n",
       " '▁comple',\n",
       " 'tes',\n",
       " '▁the',\n",
       " '▁request',\n",
       " '.',\n",
       " '<0x0A>',\n",
       " '<0x0A>',\n",
       " '##',\n",
       " '#',\n",
       " '▁Inst',\n",
       " 'ruction',\n",
       " ':',\n",
       " '<0x0A>',\n",
       " 'Det',\n",
       " 'erm',\n",
       " 'ine',\n",
       " '▁the',\n",
       " '▁Pro',\n",
       " 'k',\n",
       " 'ary',\n",
       " 'otic',\n",
       " '▁Prote',\n",
       " 'in',\n",
       " '▁Sub',\n",
       " 'cell',\n",
       " 'ular',\n",
       " '▁Location',\n",
       " '▁of',\n",
       " '▁following',\n",
       " '▁protein',\n",
       " '▁sequence',\n",
       " ',',\n",
       " '▁The',\n",
       " '▁result',\n",
       " '▁will',\n",
       " '▁be',\n",
       " '▁one',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁following',\n",
       " ':',\n",
       " '▁C',\n",
       " 'Y',\n",
       " 'top',\n",
       " 'las',\n",
       " 'mic',\n",
       " 'M',\n",
       " 'emb',\n",
       " 'rane',\n",
       " ',',\n",
       " 'Cell',\n",
       " 'wall',\n",
       " ',',\n",
       " 'Cy',\n",
       " 'top',\n",
       " 'las',\n",
       " 'mic',\n",
       " ',',\n",
       " 'Ext',\n",
       " 'rac',\n",
       " 'ell',\n",
       " 'ular',\n",
       " ',',\n",
       " 'Out',\n",
       " 'er',\n",
       " 'M',\n",
       " 'emb',\n",
       " 'rane',\n",
       " ',',\n",
       " 'Per',\n",
       " 'i',\n",
       " 'pl',\n",
       " 'asm',\n",
       " 'ic',\n",
       " '.',\n",
       " '<0x0A>',\n",
       " '<0x0A>',\n",
       " '##',\n",
       " '#',\n",
       " '▁Input',\n",
       " ':',\n",
       " '<0x0A>',\n",
       " 'MKI',\n",
       " 'GI',\n",
       " 'PKEI',\n",
       " 'K',\n",
       " 'NN',\n",
       " 'EN',\n",
       " 'RV',\n",
       " 'AMTP',\n",
       " 'AGVV',\n",
       " 'S',\n",
       " 'LTH',\n",
       " 'AG',\n",
       " 'HER',\n",
       " 'LAI',\n",
       " 'ETGG',\n",
       " 'GI',\n",
       " 'G',\n",
       " 'SSFT',\n",
       " 'DA',\n",
       " 'EYV',\n",
       " 'AAG',\n",
       " 'AAY',\n",
       " 'RCI',\n",
       " 'GK',\n",
       " 'EA',\n",
       " 'WAQ',\n",
       " 'EM',\n",
       " 'ILK',\n",
       " 'VK',\n",
       " 'EPV',\n",
       " 'ASEY',\n",
       " 'DY',\n",
       " 'FY',\n",
       " 'EGQI',\n",
       " 'LF',\n",
       " 'T',\n",
       " 'YLH',\n",
       " 'LAP',\n",
       " 'RAE',\n",
       " 'L',\n",
       " 'TQ',\n",
       " 'ALI',\n",
       " 'DKK',\n",
       " 'VVGI',\n",
       " 'AY',\n",
       " 'ETV',\n",
       " 'QL',\n",
       " 'AN',\n",
       " 'GS',\n",
       " 'LP',\n",
       " 'LLTP',\n",
       " 'MSEV',\n",
       " 'AGKM',\n",
       " 'AT',\n",
       " 'QIG',\n",
       " 'AQ',\n",
       " 'YLEK',\n",
       " 'N',\n",
       " 'HGG',\n",
       " 'KGI',\n",
       " 'LLGG',\n",
       " 'VS',\n",
       " 'GV',\n",
       " 'H',\n",
       " 'ARKV',\n",
       " 'TVI',\n",
       " 'GGGI',\n",
       " 'AGT',\n",
       " 'NA',\n",
       " 'AKI',\n",
       " 'AVG',\n",
       " 'MG',\n",
       " 'ADV',\n",
       " 'TVID',\n",
       " 'LSP',\n",
       " 'ER',\n",
       " 'L',\n",
       " 'RQLE',\n",
       " 'D',\n",
       " 'MFG',\n",
       " 'RDV',\n",
       " 'QT',\n",
       " 'L',\n",
       " 'MS',\n",
       " 'N',\n",
       " 'PY',\n",
       " 'NI',\n",
       " 'AESV',\n",
       " 'KH',\n",
       " 'SDLV',\n",
       " 'VGAV',\n",
       " 'LIPG',\n",
       " 'AKAP',\n",
       " 'KLV',\n",
       " 'SE',\n",
       " 'EMI',\n",
       " 'QSM',\n",
       " 'QPG',\n",
       " 'SVVV',\n",
       " 'DI',\n",
       " 'A',\n",
       " 'ID',\n",
       " 'QGGI',\n",
       " 'FAT',\n",
       " 'SDRV',\n",
       " 'TTH',\n",
       " 'DDP',\n",
       " 'TYV',\n",
       " 'KHG',\n",
       " 'VV',\n",
       " 'HY',\n",
       " 'AV',\n",
       " 'AN',\n",
       " 'MPG',\n",
       " 'AVP',\n",
       " 'RTST',\n",
       " 'I',\n",
       " 'ALT',\n",
       " 'NN',\n",
       " 'TIP',\n",
       " 'Y',\n",
       " 'ALQI',\n",
       " 'AN',\n",
       " 'KG',\n",
       " 'YKQ',\n",
       " 'AC',\n",
       " 'ID',\n",
       " 'NP',\n",
       " 'ALK',\n",
       " 'KGV',\n",
       " 'N',\n",
       " 'ALEG',\n",
       " 'HIT',\n",
       " 'YK',\n",
       " 'AVA',\n",
       " 'EAQG',\n",
       " 'LPYV',\n",
       " 'N',\n",
       " 'V',\n",
       " 'DE',\n",
       " 'L',\n",
       " 'IQ',\n",
       " '<0x0A>',\n",
       " '<0x0A>',\n",
       " '##',\n",
       " '#',\n",
       " '▁Response',\n",
       " ':',\n",
       " '<0x0A>',\n",
       " 'Cy',\n",
       " 'top',\n",
       " 'las',\n",
       " 'mic']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0449aee-1ac6-4db5-873f-afdfb0fc9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=1000):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "          # return_attention_mask=True,\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    #max_length=max_output_tokens,\n",
    "    max_new_tokens=8,\n",
    "    temperature=0.01  # 控制生成的多样性\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.decode(generated_tokens_with_prompt[0], skip_special_tokens=True)\n",
    "  generated_text_answer = generated_text_with_prompt[len(text):]\n",
    "\n",
    "\n",
    "  return generated_text_answer\n",
    "\n",
    "# 如果需要进一步清理\n",
    "def clean_generated_text(text):\n",
    "    # 去除 'Ġ' 符号并替换为空格\n",
    "    text = text.replace('Ġ', ' ')\n",
    "    # 去除多余的空格\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9041426-eb59-4314-82dd-7b6d6d477783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (test): Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Determine the Prokaryotic Protein Subcellular Location of following protein sequence, The result will be one of the following: CYtoplasmicMembrane,Cellwall,Cytoplasmic,Extracellular,OuterMembrane,Periplasmic.\n",
      "\n",
      "### Input:\n",
      "MKIGIPKEIKNNENRVAMTPAGVVSLTHAGHERLAIETGGGIGSSFTDAEYVAAGAAYRCIGKEAWAQEMILKVKEPVASEYDYFYEGQILFTYLHLAPRAELTQALIDKKVVGIAYETVQLANGSLPLLTPMSEVAGKMATQIGAQYLEKNHGGKGILLGGVSGVHARKVTVIGGGIAGTNAAKIAVGMGADVTVIDLSPERLRQLEDMFGRDVQTLMSNPYNIAESVKHSDLVVGAVLIPGAKAPKLVSEEMIQSMQPGSVVVDIAIDQGGIFATSDRVTTHDDPTYVKHGVVHYAVANMPGAVPRTSTIALTNNTIPYALQIANKGYKQACIDNPALKKGVNALEGHITYKAVAEAQGLPYVNVDELIQ\n",
      "\n",
      "### Response:\n",
      "\n",
      "real answer: Cytoplasmic\n",
      "--------------------------\n",
      "\n",
      "model's answer: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.01` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periplasmic\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(data[\"test\"][0])\n",
    "\n",
    "print(\"input (test):\", input_text)\n",
    "\n",
    "print(\"real answer:\", data[\"test\"][0][\"output\"])\n",
    "\n",
    "print(\"--------------------------\\n\")\n",
    "\n",
    "print(\"model's answer: \\n\")\n",
    "print(inference(input_text, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1489173-84af-4c8e-b66b-0cdbe42c7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[\"test\"].shuffle(seed=1678).select(range(100))\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for entry in test_data:\n",
    "    input_text = format_input(entry)\n",
    "    #print(input_text)\n",
    "    response_text = inference(input_text, model, tokenizer)\n",
    "    #print(response_text)\n",
    "    data = {\n",
    "        \"instruction\":entry[\"instruction\"],\n",
    "         \"input\":entry[\"input\"],\n",
    "         \"output\":entry[\"output\"],\n",
    "        \"model_response\":response_text\n",
    "    }\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39275fe6-ac3b-4558-9f4c-2853a41d48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 定义输出文件路径\n",
    "output_file = 'llama-sft-3.json'\n",
    "\n",
    "# 将 Dataset 对象导出为 JSON 文件\n",
    "# test_data.to_json(output_file)\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(data_list, file, indent=4)  # \"indent\" for pretty-printing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffaba65-a270-4433-b234-932f5e288f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁prom oter'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenizer.tokenize(\"promoter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e373a4-6857-4874-b2da-58da2928925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYtoplasmicMembrane |||||||||||| CYtoplasmicMembrane\n",
      "NPP |||||||||||| NPP\n",
      "Conform |||||||||||| Not Conform\n",
      "Alpha plus Beta |||||||||||| All Beta\n",
      "Not Conform |||||||||||| Not Conform\n",
      "NPP |||||||||||| NPP\n",
      "Extracellular |||||||||||| Extracellular\n",
      "Not Conform |||||||||||| Conform\n",
      "Alpha plus Beta |||||||||||| All Alpha\n",
      "sec |||||||||||| sec\n",
      "Not Conform |||||||||||| Conform\n",
      "Periplasmic |||||||||||| Periplasmic\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Conform\n",
      "sec |||||||||||| sec\n",
      "Conform |||||||||||| Not Conform\n",
      "Alpha and Beta ||||||||||||  Multi-domain Proteins\n",
      "sec |||||||||||| sec\n",
      "Conform |||||||||||| Conform\n",
      "All Beta |||||||||||| Small Proteins and Peptides\n",
      "Cytoplasmic |||||||||||| Periplasmic\n",
      "CYtoplasmicMembrane |||||||||||| Jefferson Davis\n",
      "Conform |||||||||||| Conform\n",
      "NPP |||||||||||| NPP\n",
      "Alpha plus Beta |||||||||||| Alpha and Beta\n",
      "Alpha plus Beta |||||||||||| Alpha and Beta\n",
      "Not Conform |||||||||||| Conform\n",
      "tat |||||||||||| tat\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Conform\n",
      "Alpha and Beta |||||||||||| Multi-domain Proteins\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Conform\n",
      "All Beta |||||||||||| Alpha plus Beta\n",
      "Not Conform |||||||||||| Conform\n",
      "sec |||||||||||| sec\n",
      "Conform |||||||||||| Not Conform\n",
      "Not Conform |||||||||||| Not Conform\n",
      "Not Conform |||||||||||| Not Conform\n",
      "sec |||||||||||| sec\n",
      "NPP |||||||||||| NPP\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Conform\n",
      "Extracellular |||||||||||| OuterMembrane\n",
      "sec |||||||||||| sec\n",
      "All Alpha |||||||||||| All Beta\n",
      "Alpha plus Beta |||||||||||| Alpha plus Beta\n",
      "CYtoplasmicMembrane |||||||||||| CYtoplasmicMembrane\n",
      "Not Conform |||||||||||| Not Conform\n",
      "Alpha and Beta |||||||||||| All Beta\n",
      "Alpha and Beta ||||||||||||  Multi-domain Proteins\n",
      "CYtoplasmicMembrane |||||||||||| CYtoplasmicMembrane\n",
      "OuterMembrane |||||||||||| CYtoplasmicMembrane\n",
      "sec |||||||||||| sec\n",
      "All Alpha |||||||||||| Alpha plus Beta\n",
      "Alpha plus Beta |||||||||||| All Beta\n",
      "Conform |||||||||||| Conform\n",
      "sec |||||||||||| sec\n",
      "Conform |||||||||||| Conform\n",
      "Cytoplasmic |||||||||||| Periplasmic\n",
      "Not Conform |||||||||||| Determine Whether the Following Mito\n",
      "Not Conform |||||||||||| Conform\n",
      "Alpha and Beta |||||||||||| Multi-domain Proteins\n",
      "Small Proteins and Peptides |||||||||||| Small Proteins and Peptides\n",
      "Extracellular |||||||||||| Periplasmic\n",
      "Small Proteins and Peptides |||||||||||| All Beta\n",
      "CYtoplasmicMembrane |||||||||||| Masontask\n",
      "Not Conform |||||||||||| Conform\n",
      "Conform |||||||||||| Conform\n",
      "Cytoplasmic |||||||||||| Periplasmic\n",
      "Cytoplasmic |||||||||||| Periplasmic\n",
      "Alpha plus Beta |||||||||||| Alpha plus Beta\n",
      "Alpha and Beta |||||||||||| Alpha and Beta\n",
      "NPP |||||||||||| NPP\n",
      "Not Conform |||||||||||| Not Conform\n",
      "CYtoplasmicMembrane |||||||||||| CYtoplasmicMembrane\n",
      "CYtoplasmicMembrane |||||||||||| CYtoplasmicMembrane\n",
      "Cytoplasmic |||||||||||| Periplasmic\n",
      "Not Conform |||||||||||| Conform\n",
      "sec |||||||||||| sec\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Not Conform\n",
      "Alpha and Beta |||||||||||| Multi-domain Proteins\n",
      "Not Conform |||||||||||| Conform\n",
      "Extracellular ||||||||||||  Cellwall\n",
      "Not Conform |||||||||||| Conform\n",
      "Alpha and Beta |||||||||||| All Alpha\n",
      "Alpha and Beta |||||||||||| Alpha plus Beta\n",
      "Multi-domain Proteins ||||||||||||  Multi-domain Proteins\n",
      "Alpha and Beta |||||||||||| All Alpha\n",
      "All Beta |||||||||||| Alpha plus Beta\n",
      "Cytoplasmic |||||||||||| CYtoplasmicMembrane\n",
      "All Beta |||||||||||| All Alpha\n",
      "Not Conform |||||||||||| Conform\n",
      "Not Conform |||||||||||| Determine Whether the Following DNA Se\n",
      "Not Conform |||||||||||| Not Conform\n",
      "non-NPP |||||||||||| non-NPP\n",
      "All Alpha |||||||||||| All Alpha\n",
      "CYtoplasmicMembrane |||||||||||| Maryland\n",
      "presicion 0.44 same 0.4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "with open(output_file, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "all_num = len(test_data)\n",
    "right_sum = 0\n",
    "same_sum = 0\n",
    "for item in test_data:\n",
    "    output = item[\"output\"]\n",
    "    #output = \" \".join(tokenizer.tokenize(output))\n",
    "    model_response = item[\"model_response\"]\n",
    "\n",
    "    print(output,\"||||||||||||\", model_response)\n",
    "\n",
    "    if model_response == output: #same it\n",
    "        same_sum = same_sum + 1\n",
    "        \n",
    "    if output.find(\"Non\")==-1: # no Non\n",
    "        if model_response.find(output)!=-1 and model_response.find(\"Non\")==-1: #find it, but no Non\n",
    "            right_sum = right_sum + 1\n",
    "    else:\n",
    "        if model_response.find(output)!=-1: #find it\n",
    "            right_sum = right_sum + 1\n",
    "\n",
    "\n",
    "print(\"presicion\", right_sum/all_num, \"same\", same_sum/all_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d46f3-2f5b-4e55-ae41-081d5195f5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
